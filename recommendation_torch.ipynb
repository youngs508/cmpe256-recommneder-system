{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1adce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Declarations for libraries used in this code ###\n",
    "import csv \n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix as coo\n",
    "from sklearn.decomposition import TruncatedSVD as Tr\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9fabdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition for binary utility matrix ###\n",
    "def binary_utility_matrix(user_ids, item_ids):\n",
    "    items = set()\n",
    "    for lst in item_ids: \n",
    "        items.update(lst)\n",
    "    a = {user:item for item,user in enumerate(list(dict.fromkeys(user_ids)))}\n",
    "    b = {item:i for i,item in enumerate(sorted(items))}\n",
    "    rows, cols, data = list(), list(), list()\n",
    "    for user_id, item_id in zip(user_ids, item_ids):\n",
    "        user = a[user_id]\n",
    "        for it in item_id:\n",
    "            rows.append(user) \n",
    "            cols.append(b.get(it)) \n",
    "            data.append(1.0)\n",
    "    user_id = coo((data, (rows, cols)), shape=(len(a), len(b)), dtype=np.float32).tocsr()\n",
    "    user_id.data[:] = 1.0\n",
    "    user_id.eliminate_zeros()\n",
    "    return user_id, {item:user for user,item in a.items()}, {i:item for item,i in b.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0d32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition about Item-Based kNN algorithm and 20 item recommendation ###\n",
    "# Compute Item-Item Similarity (the \"KNN\" step)\n",
    "def item_based_knn(user_id, k, batch, n_components, n, idx2iid):\n",
    "    User, Item = user_id.shape\n",
    "    Dimention = min(n_components, max(2, min(User, Item)-1))\n",
    "    # SVD projects hugh item vectors (size: 31667) into a compact latent space where similar items stay close -\n",
    "    # it's still item-based kNN, but using learned embeddings instead of raw co-occurrence vectors.\n",
    "    # In this code, svd option is already set True. \n",
    "    # This speeds up computation, reduces memory/VRAM, and slightly smooths noisy similarities.\n",
    "    svd = Tr(n_components=Dimention, random_state=42)\n",
    "    X_np = svd.fit_transform(user_id.T).astype(np.float32, copy=False) \n",
    "    rn = np.linalg.norm(X_np, axis=1, keepdims=True)\n",
    "    rn[rn < 1e-12] = 1.0\n",
    "    # X_np / rn converts item vectors to unit length.\n",
    "    # So, their dot product equals cosine similarity.\n",
    "    Tor = torch.from_numpy(X_np / rn).to(device)                     \n",
    "    rows, cols, data = list(), list(), list()\n",
    "    with torch.inference_mode():\n",
    "        for st in range(0, Tor.shape[0], batch):     \n",
    "            # Compute similarities on the GPU.   \n",
    "            # All pairwise cosine similarities between Q (Tor[st:min(Tor.shape[0], st + batch)])'s items and all items.\n",
    "            # Do it in batches to avoid exceeding GPU memory.        \n",
    "            sims = Tor[st:min(Tor.shape[0], st + batch)] @ Tor.t().contiguous()                     \n",
    "            row_idx = torch.arange(min(Tor.shape[0], st + batch) - st, device=device)\n",
    "            col_idx = torch.arange(st, min(Tor.shape[0], st + batch), device=device)\n",
    "            sims[row_idx, col_idx] = float('-inf')\n",
    "            # Keep only the top-k neighbors per item.\n",
    "            # For each item, we store the k most similar items with the highest cosine similarity.\n",
    "            # The result is a sparse item-item similarity matrix Sa, where each item has up to k neighbors. \n",
    "            vals, idx = torch.topk(sims, k=min(k, max(1, Tor.shape[0]-1)), dim=1, largest=True, sorted=False)\n",
    "            idx_np = idx.cpu().numpy()\n",
    "            vals_np = vals.cpu().numpy().astype(np.float32)\n",
    "            for i in range(min(Tor.shape[0], st + batch) - st):\n",
    "                gi = st + i\n",
    "                for j, s in zip(idx_np[i], vals_np[i]):\n",
    "                    if np.isfinite(s) and s > 0.0:\n",
    "                        rows.append(gi)\n",
    "                        cols.append(int(j)) \n",
    "                        data.append(float(s))\n",
    "    Sa = coo((data, (rows, cols)), shape=(Tor.shape[0], Tor.shape[0]), dtype=np.float32).tocsr()\n",
    "    Sa.setdiag(0.0)\n",
    "    Sa.eliminate_zeros()\n",
    "    # Once we have Sa (item similarities), the recommender predicts how much a user u would like each unseen item.\n",
    "    # user_id = (users x items): what each user has interacted with (1s and 0s).\n",
    "    # Sa = (items x items): similarity between items.\n",
    "    scores = (user_id @ Sa).tolil()   \n",
    "    ui_csr = user_id.tocsr()\n",
    "    for user in range(ui_csr.shape[0]):\n",
    "        begin, finish = ui_csr.indptr[user], ui_csr.indptr[user+1]\n",
    "        for j in ui_csr.indices[begin:finish]:\n",
    "            scores[user, j] = -np.inf\n",
    "    scores = scores.tocsr()\n",
    "    popular = np.argsort(-np.asarray(user_id.sum(axis=0)).ravel())\n",
    "    recs = dict()\n",
    "    for user in range(scores.shape[0]):\n",
    "        good = [(j, s) for j, s in zip(scores.getrow(user).indices, scores.getrow(user).data) if np.isfinite(s)]\n",
    "        if len(good) > n:\n",
    "            # After similarity scores for candidate items are obtained,\n",
    "            # quickly finds the indices of the top-n scores (partial sort).\n",
    "            top = [good[k] for k in np.argpartition(np.array([g[1] for g in good]), -n)[-n:]]\n",
    "            top.sort(key=lambda x: -x[1])\n",
    "            js = [j for j,k in top]\n",
    "        else:\n",
    "            good.sort(key=lambda x: -x[1])\n",
    "            js = [j for j,k in good][:n]\n",
    "        if len(js) < n:\n",
    "            seen = set(ui_csr.indices[ui_csr.indptr[user]:ui_csr.indptr[user+1]])\n",
    "            for p in popular:\n",
    "                # Users shouldn't be recommended items they've already interacted with.\n",
    "                if p in seen or p in js: \n",
    "                    continue\n",
    "                js.append(p)\n",
    "                if len(js) >= n: \n",
    "                    break\n",
    "        # For each user u, we take the Top-N highest-scoring unseen items.\n",
    "        recs[user] = [idx2iid[j] for j in js[:n]]\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a931e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ### Insert dataset ###\n",
    "    user_ids, item_ids = list(), list()\n",
    "    with open(\"train-1.txt\", \"r\", encoding=\"utf-8\") as g:\n",
    "        for lin in g:\n",
    "            tokens = [t for t in lin.split() if t is not None]\n",
    "            user_ids.append(tokens[0])\n",
    "            item_ids.append(list(dict.fromkeys(tokens[1:])))\n",
    "\n",
    "    ### Build binary utility matrix ###\n",
    "    ui, uid, iid = binary_utility_matrix(user_ids, item_ids)\n",
    "\n",
    "    ### Recommend 20 items per user using item-based kNN ###\n",
    "    recs = item_based_knn(ui, k=100, batch=200000, n_components=256, n=20, idx2iid=iid)\n",
    "    \n",
    "    ### The recommended items are written in recommendations.csv file ###\n",
    "    with open(\"recommendations.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as g:\n",
    "        w = csv.writer(g)\n",
    "        w.writerow([\"user_id\", \"recommendations\"])\n",
    "        for uidx in range(len(uid)):\n",
    "            ints = [int(num) for num in recs[uidx]]\n",
    "            ints.sort()  # Written in ascending order\n",
    "            w.writerow([uid[uidx], \" \".join(map(str, ints))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c98558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
